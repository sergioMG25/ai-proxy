# ğŸ“® ColecciÃ³n de Postman - AI Proxy

Esta colecciÃ³n de Postman te permite probar fÃ¡cilmente todos los endpoints del AI Proxy.

## ğŸ“¥ Importar la ColecciÃ³n

1. Abre Postman
2. Click en **Import** (Importar)
3. Selecciona el archivo `AI-Proxy.postman_collection.json`
4. La colecciÃ³n "AI Proxy API" aparecerÃ¡ en tu panel izquierdo

## ğŸ”§ ConfiguraciÃ³n

### Variables de Entorno

La colecciÃ³n incluye una variable por defecto:

- `baseUrl`: `http://localhost:3001`

**Para cambiar el servidor:**

1. En Postman, selecciona la colecciÃ³n "AI Proxy API"
2. Ve a la pestaÃ±a **Variables**
3. Modifica el valor de `baseUrl` segÃºn sea necesario:
   - Local: `http://localhost:3001`
   - ProducciÃ³n: `https://tu-servidor.com`
   - Dokploy: `https://tu-dominio.dokploy.com`

## ğŸ“‹ Peticiones Incluidas

### 1. **Health Check** ğŸ¥

Verifica el estado del servidor y obtiene estadÃ­sticas.

**MÃ©todo:** `GET /health`

**Tests automÃ¡ticos:**

- âœ… CÃ³digo de estado 200
- âœ… Status es "healthy"

---

### 2. **Chat - Groq** ğŸ¦™

PeticiÃ³n usando el servicio Groq con llama3-8b-8192.

**MÃ©todo:** `POST /chat`

**Body:**

```json
{
  "messages": [
    {
      "role": "user",
      "content": "Explica quÃ© es la inteligencia artificial en una frase corta"
    }
  ],
  "service": "groq",
  "model": "llama3-8b-8192"
}
```

**Tests automÃ¡ticos:**

- âœ… CÃ³digo de estado 200
- âœ… Respuesta contiene contenido
- âœ… Servicio usado es Groq

---

### 3. **Chat - Cerebras** ğŸ§ 

PeticiÃ³n usando el servicio Cerebras con llama3.1-8b.

**MÃ©todo:** `POST /chat`

**Body:**

```json
{
  "messages": [
    {
      "role": "user",
      "content": "Â¿CuÃ¡l es la capital de Francia?"
    }
  ],
  "service": "cerebras",
  "model": "llama3.1-8b"
}
```

**Tests automÃ¡ticos:**

- âœ… CÃ³digo de estado 200
- âœ… Respuesta contiene contenido
- âœ… Servicio usado es Cerebras

---

### 4. **Chat - Gemini** âœ¨

PeticiÃ³n usando el servicio Gemini con gemini-2.0-flash-exp.

**MÃ©todo:** `POST /chat`

**Body:**

```json
{
  "messages": [
    {
      "role": "user",
      "content": "Escribe un haiku sobre la programaciÃ³n"
    }
  ],
  "service": "gemini",
  "model": "gemini-2.0-flash-exp"
}
```

**Tests automÃ¡ticos:**

- âœ… CÃ³digo de estado 200
- âœ… Respuesta contiene contenido
- âœ… Servicio usado es Gemini

---

### 5. **Chat - Auto (Round-Robin)** ğŸ”„

PeticiÃ³n sin especificar servicio. El sistema distribuye la carga automÃ¡ticamente.

**MÃ©todo:** `POST /chat`

**Body:**

```json
{
  "messages": [
    {
      "role": "user",
      "content": "Dame un dato curioso sobre el espacio"
    }
  ]
}
```

**Tests automÃ¡ticos:**

- âœ… CÃ³digo de estado 200
- âœ… Respuesta contiene contenido
- âœ… Servicio seleccionado automÃ¡ticamente (Groq, Cerebras o Gemini)

---

### 6. **Chat - ConversaciÃ³n Multi-turno** ğŸ’¬

Ejemplo de conversaciÃ³n con mÃºltiples mensajes manteniendo contexto.

**MÃ©todo:** `POST /chat`

**Body:**

```json
{
  "messages": [
    {
      "role": "user",
      "content": "Â¿CuÃ¡l es la capital de EspaÃ±a?"
    },
    {
      "role": "assistant",
      "content": "La capital de EspaÃ±a es Madrid."
    },
    {
      "role": "user",
      "content": "Â¿CuÃ¡ntos habitantes tiene aproximadamente?"
    }
  ],
  "service": "groq"
}
```

---

### 7. **Chat - Con ParÃ¡metros Avanzados** âš™ï¸

Ejemplo usando temperatura, max_tokens y mensaje de sistema.

**MÃ©todo:** `POST /chat`

**Body:**

```json
{
  "messages": [
    {
      "role": "system",
      "content": "Eres un asistente experto en historia."
    },
    {
      "role": "user",
      "content": "CuÃ©ntame sobre la RevoluciÃ³n Francesa en 3 puntos"
    }
  ],
  "service": "gemini",
  "model": "gemini-2.0-flash-exp",
  "temperature": 0.7,
  "max_tokens": 500
}
```

## ğŸ§ª Tests AutomÃ¡ticos

Todas las peticiones incluyen tests automÃ¡ticos que se ejecutan despuÃ©s de cada request:

- ValidaciÃ³n de cÃ³digos de estado HTTP
- VerificaciÃ³n de estructura de respuesta
- ValidaciÃ³n de servicios utilizados

**Para ver resultados de tests:**

1. Ejecuta una peticiÃ³n
2. Ve a la pestaÃ±a **Test Results** en la respuesta
3. VerÃ¡s âœ… tests pasados y âŒ tests fallidos

## ğŸš€ Uso RÃ¡pido

1. **Importa** la colecciÃ³n
2. **AsegÃºrate** de que el servidor estÃ© corriendo (`bun run index.ts`)
3. **Ejecuta** cualquier peticiÃ³n haciendo click en **Send**
4. **Revisa** la respuesta y los tests automÃ¡ticos

## ğŸ“¦ Runner de ColecciÃ³n

Para ejecutar todas las peticiones automÃ¡ticamente:

1. Click derecho en "AI Proxy API"
2. Selecciona **Run collection**
3. Click en **Run AI Proxy API**
4. VerÃ¡s todas las peticiones ejecutarse en secuencia con sus resultados

## ğŸ’¡ Tips

- Usa **Ctrl+Enter** (Windows) o **Cmd+Enter** (Mac) para enviar peticiones rÃ¡pidamente
- Guarda respuestas interesantes como **Examples** para referencia futura
- Crea **Environments** separados para desarrollo, staging y producciÃ³n
- Duplica peticiones para crear variaciones con diferentes parÃ¡metros

## ğŸ”— Enlaces Ãštiles

- [DocumentaciÃ³n Principal](README.md)
- [DocumentaciÃ³n Docker](DOCKER.md)
- [API de Postman](https://learning.postman.com/)
